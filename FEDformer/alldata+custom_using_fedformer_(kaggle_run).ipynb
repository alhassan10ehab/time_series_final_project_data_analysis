{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-28T13:26:44.657365Z",
     "iopub.status.busy": "2023-07-28T13:26:44.656835Z",
     "iopub.status.idle": "2023-07-28T13:26:58.691540Z",
     "shell.execute_reply": "2023-07-28T13:26:58.690355Z",
     "shell.execute_reply.started": "2023-07-28T13:26:44.657332Z"
    },
    "id": "UrnO3EuPSMa2",
    "outputId": "839f211f-e495-4d1c-c1cb-b820159f047d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "Successfully installed einops-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-28T13:26:58.694511Z",
     "iopub.status.busy": "2023-07-28T13:26:58.694140Z",
     "iopub.status.idle": "2023-07-28T13:27:01.018819Z",
     "shell.execute_reply": "2023-07-28T13:27:01.017106Z",
     "shell.execute_reply.started": "2023-07-28T13:26:58.694475Z"
    },
    "id": "b9CXUFKTRtnh",
    "outputId": "992b031b-60f3-4ab8-d92e-bf98cb40d420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'LTSF-Linear'...\n",
      "remote: Enumerating objects: 387, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "remote: Total 387 (delta 36), reused 56 (delta 31), pack-reused 312\u001b[K\n",
      "Receiving objects: 100% (387/387), 5.83 MiB | 18.47 MiB/s, done.\n",
      "Resolving deltas: 100% (180/180), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cure-lab/LTSF-Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-28T13:27:01.020833Z",
     "iopub.status.busy": "2023-07-28T13:27:01.020438Z",
     "iopub.status.idle": "2023-07-28T13:27:03.423903Z",
     "shell.execute_reply": "2023-07-28T13:27:03.422688Z",
     "shell.execute_reply.started": "2023-07-28T13:27:01.020773Z"
    },
    "id": "SgpqaF9sR3hC",
    "outputId": "abc9a95a-8c06-4579-be46-f1de8b3acb79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ETDataset'...\n",
      "remote: Enumerating objects: 187, done.\u001b[K\n",
      "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 187 (delta 25), reused 20 (delta 20), pack-reused 159\u001b[K\n",
      "Receiving objects: 100% (187/187), 3.86 MiB | 16.45 MiB/s, done.\n",
      "Resolving deltas: 100% (62/62), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zhouhaoyi/ETDataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7u7CvGrPxzf"
   },
   "source": [
    "## ETTm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2fBZzC7SAsB",
    "outputId": "64f08ea9-5a34-4074-a40f-0986b481b21d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "\n",
      "Namespace(is_training=1, task_id='ETTm1', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTm1', root_path='/content/ETDataset/ETT-small', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=24, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "\n",
      "Use GPU: cuda:0\n",
      "\n",
      "fourier enhanced block used!\n",
      "\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "\n",
      "fourier enhanced block used!\n",
      "\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "\n",
      " fourier enhanced cross attention used!\n",
      "\n",
      "modes_q=36, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
      "\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "\n",
      "enc_modes: 48, dec_modes: 36\n",
      "\n",
      ">>>>>>>start training : ETTm1_FEDformer_random_modes64_ETTm1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "train 34441\n",
      "\n",
      "val 11497\n",
      "\n",
      "test 11497\n",
      "\n",
      "Epoch: 1 cost time: 370.7472038269043\n",
      "\n",
      "Epoch: 1, Steps: 1076 | Train Loss: 0.2789548 Vali Loss: 0.3100280 Test Loss: 0.3027889\n",
      "\n",
      "Validation loss decreased (inf --> 0.310028).  Saving model ...\n",
      "\n",
      "Updating learning rate to 0.0001\n",
      "\n",
      "Epoch: 2 cost time: 363.9195749759674\n",
      "\n",
      "Epoch: 2, Steps: 1076 | Train Loss: 0.2077285 Vali Loss: 0.2900716 Test Loss: 0.2896363\n",
      "\n",
      "Validation loss decreased (0.310028 --> 0.290072).  Saving model ...\n",
      "\n",
      "Updating learning rate to 5e-05\n",
      "\n",
      "Epoch: 3 cost time: 363.5699450969696\n",
      "\n",
      "Epoch: 3, Steps: 1076 | Train Loss: 0.1892625 Vali Loss: 0.2830447 Test Loss: 0.2888688\n",
      "\n",
      "Validation loss decreased (0.290072 --> 0.283045).  Saving model ...\n",
      "\n",
      "Updating learning rate to 2.5e-05\n",
      "\n",
      "Epoch: 4 cost time: 362.73040556907654\n",
      "\n",
      "Epoch: 4, Steps: 1076 | Train Loss: 0.1814372 Vali Loss: 0.2805125 Test Loss: 0.2825319\n",
      "\n",
      "Validation loss decreased (0.283045 --> 0.280512).  Saving model ...\n",
      "\n",
      "Updating learning rate to 1.25e-05\n",
      "\n",
      "Epoch: 5 cost time: 362.8184926509857\n",
      "\n",
      "Epoch: 5, Steps: 1076 | Train Loss: 0.1779459 Vali Loss: 0.2788908 Test Loss: 0.2822799\n",
      "\n",
      "Validation loss decreased (0.280512 --> 0.278891).  Saving model ...\n",
      "\n",
      "Updating learning rate to 6.25e-06\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "       # ETTm1\n",
    "        os.system(f\"python -u /kaggle/working/FEDformer/run.py \"\n",
    "                  f\"--is_training 1 \"\n",
    "                  f\"--root_path /kaggle/working/ETDataset/ETT-small \"\n",
    "                  f\"--data_path ETTm1.csv \"\n",
    "                  f\"--task_id ETTm1 \"\n",
    "                  f\"--model FEDformer \"\n",
    "                  f\"--data ETTm1 \"\n",
    "                  f\"--features M \"\n",
    "                  f\"--seq_len 96 \"\n",
    "                  f\"--label_len 48 \"\n",
    "                  f\"--pred_len {pre_len} \"\n",
    "                  f\"--e_layers 2 \"\n",
    "                  f\"--d_layers 1 \"\n",
    "                  f\"--factor 3 \"\n",
    "                  f\"--enc_in 7 \"\n",
    "                  f\"--dec_in 7 \"\n",
    "                  f\"--c_out 7 \"\n",
    "                  f\"--des 'Exp' \"\n",
    "                  f\"--d_model 512 \"\n",
    "                  f\"--itr 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD7bS4zIRw7m"
   },
   "source": [
    "## ETTm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T17:38:41.950819Z",
     "iopub.status.busy": "2023-07-15T17:38:41.950487Z"
    },
    "id": "9G5cNOnSN3Au",
    "outputId": "bdc47692-bce9-486a-ea07-df461e0b3df6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTm2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTm2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34369\n",
      "val 11425\n",
      "test 11425\n",
      "Epoch: 1 cost time: 297.1413371562958\n",
      "Epoch: 1, Steps: 1074 | Train Loss: 0.2665378 Vali Loss: 0.1371424 Test Loss: 0.1962818\n",
      "Validation loss decreased (inf --> 0.137142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 291.32367753982544\n",
      "Epoch: 2, Steps: 1074 | Train Loss: 0.2300426 Vali Loss: 0.1369413 Test Loss: 0.1938625\n",
      "Validation loss decreased (0.137142 --> 0.136941).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 291.26797318458557\n",
      "Epoch: 3, Steps: 1074 | Train Loss: 0.2201165 Vali Loss: 0.1340727 Test Loss: 0.1903218\n",
      "Validation loss decreased (0.136941 --> 0.134073).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 291.31471824645996\n",
      "Epoch: 4, Steps: 1074 | Train Loss: 0.2160542 Vali Loss: 0.1340157 Test Loss: 0.1899994\n",
      "Validation loss decreased (0.134073 --> 0.134016).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 291.3345899581909\n",
      "Epoch: 5, Steps: 1074 | Train Loss: 0.2140444 Vali Loss: 0.1343900 Test Loss: 0.1906406\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 290.9541549682617\n",
      "Epoch: 6, Steps: 1074 | Train Loss: 0.2128763 Vali Loss: 0.1337172 Test Loss: 0.1899888\n",
      "Validation loss decreased (0.134016 --> 0.133717).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 290.76739263534546\n",
      "Epoch: 7, Steps: 1074 | Train Loss: 0.2124197 Vali Loss: 0.1345677 Test Loss: 0.1902147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 290.7318522930145\n",
      "Epoch: 8, Steps: 1074 | Train Loss: 0.2121446 Vali Loss: 0.1341724 Test Loss: 0.1900832\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 290.6419036388397\n",
      "Epoch: 9, Steps: 1074 | Train Loss: 0.2118857 Vali Loss: 0.1341794 Test Loss: 0.1901239\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "test shape: (357, 32, 96, 7) (357, 32, 96, 7)\n",
      "test shape: (11424, 96, 7) (11424, 96, 7)\n",
      "mse:0.18998877704143524, mae:0.2834338843822479\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34369\n",
      "val 11425\n",
      "test 11425\n",
      "Epoch: 1 cost time: 292.05505633354187\n",
      "Epoch: 1, Steps: 1074 | Train Loss: 0.2683370 Vali Loss: 0.1404408 Test Loss: 0.1995792\n",
      "Validation loss decreased (inf --> 0.140441).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 292.1346538066864\n",
      "Epoch: 2, Steps: 1074 | Train Loss: 0.2311424 Vali Loss: 0.1363327 Test Loss: 0.1918388\n",
      "Validation loss decreased (0.140441 --> 0.136333).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 291.9267067909241\n",
      "Epoch: 3, Steps: 1074 | Train Loss: 0.2209095 Vali Loss: 0.1326569 Test Loss: 0.1889816\n",
      "Validation loss decreased (0.136333 --> 0.132657).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 291.86584854125977\n",
      "Epoch: 4, Steps: 1074 | Train Loss: 0.2175354 Vali Loss: 0.1335931 Test Loss: 0.1899557\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 292.05825328826904\n",
      "Epoch: 5, Steps: 1074 | Train Loss: 0.2154328 Vali Loss: 0.1332007 Test Loss: 0.1898405\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 292.50979232788086\n",
      "Epoch: 6, Steps: 1074 | Train Loss: 0.2141576 Vali Loss: 0.1329704 Test Loss: 0.1894165\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "test shape: (357, 32, 96, 7) (357, 32, 96, 7)\n",
      "test shape: (11424, 96, 7) (11424, 96, 7)\n",
      "mse:0.18898166716098785, mae:0.28018441796302795\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34369\n",
      "val 11425\n",
      "test 11425\n",
      "Epoch: 1 cost time: 291.5459997653961\n",
      "Epoch: 1, Steps: 1074 | Train Loss: 0.2683291 Vali Loss: 0.1441775 Test Loss: 0.2035917\n",
      "Validation loss decreased (inf --> 0.144178).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 291.8263063430786\n",
      "Epoch: 2, Steps: 1074 | Train Loss: 0.2312434 Vali Loss: 0.1333881 Test Loss: 0.1896030\n",
      "Validation loss decreased (0.144178 --> 0.133388).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 291.6077551841736\n",
      "Epoch: 3, Steps: 1074 | Train Loss: 0.2216142 Vali Loss: 0.1347068 Test Loss: 0.1902423\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 291.54927229881287\n",
      "Epoch: 4, Steps: 1074 | Train Loss: 0.2174075 Vali Loss: 0.1337412 Test Loss: 0.1899053\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 291.4175169467926\n",
      "Epoch: 1 cost time: 338.6687550544739\n",
      "Epoch: 1, Steps: 1071 | Train Loss: 0.3555189 Vali Loss: 0.1800835 Test Loss: 0.2628902\n",
      "Validation loss decreased (inf --> 0.180084).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 337.61993527412415\n",
      "Epoch: 2, Steps: 1071 | Train Loss: 0.3272068 Vali Loss: 0.1792272 Test Loss: 0.2619403\n",
      "Validation loss decreased (0.180084 --> 0.179227).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 337.48886823654175\n",
      "Epoch: 3, Steps: 1071 | Train Loss: 0.3134688 Vali Loss: 0.1779645 Test Loss: 0.2596828\n",
      "Validation loss decreased (0.179227 --> 0.177964).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 336.87465834617615\n",
      "Epoch: 4, Steps: 1071 | Train Loss: 0.3079595 Vali Loss: 0.1761738 Test Loss: 0.2559029\n",
      "Validation loss decreased (0.177964 --> 0.176174).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 336.6097791194916\n",
      "Epoch: 5, Steps: 1071 | Train Loss: 0.3052939 Vali Loss: 0.1776356 Test Loss: 0.2579685\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 337.0053939819336\n",
      "Epoch: 6, Steps: 1071 | Train Loss: 0.3038004 Vali Loss: 0.1770908 Test Loss: 0.2563336\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 336.9220082759857\n",
      "Epoch: 7, Steps: 1071 | Train Loss: 0.3032035 Vali Loss: 0.1772020 Test Loss: 0.2571965\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11329\n",
      "test shape: (354, 32, 192, 7) (354, 32, 192, 7)\n",
      "test shape: (11328, 192, 7) (11328, 192, 7)\n",
      "mse:0.2559029459953308, mae:0.32423263788223267\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 3, 4, 7, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 26, 27, 30, 31, 34, 36, 37, 38, 42, 43, 45, 46, 51, 54, 58, 59, 62, 63, 65, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 85, 88, 89, 90, 91, 95, 96, 97, 98, 101, 103, 109, 110, 111, 113, 115, 116, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 10, 12, 16, 20, 22, 23, 24, 26, 27, 28, 31, 32, 34, 38, 43, 44, 45, 46, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 64, 66, 69, 70, 73, 80, 81, 82, 84, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 105, 108, 109, 111, 112, 114, 115, 116, 119]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34273\n",
      "val 11329\n",
      "test 11329\n",
      "Epoch: 1 cost time: 335.9493532180786\n",
      "Epoch: 1, Steps: 1071 | Train Loss: 0.3584469 Vali Loss: 0.1777054 Test Loss: 0.2640519\n",
      "Validation loss decreased (inf --> 0.177705).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 336.9065651893616\n",
      "Epoch: 2, Steps: 1071 | Train Loss: 0.3305564 Vali Loss: 0.1772164 Test Loss: 0.2613245\n",
      "Validation loss decreased (0.177705 --> 0.177216).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 336.4904227256775\n",
      "Epoch: 3, Steps: 1071 | Train Loss: 0.3141317 Vali Loss: 0.1792009 Test Loss: 0.2618581\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 336.4992232322693\n",
      "Epoch: 4, Steps: 1071 | Train Loss: 0.3074174 Vali Loss: 0.1793804 Test Loss: 0.2622580\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 336.6621980667114\n",
      "Epoch: 5, Steps: 1071 | Train Loss: 0.3039151 Vali Loss: 0.1786314 Test Loss: 0.2608061\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11329\n",
      "test shape: (354, 32, 192, 7) (354, 32, 192, 7)\n",
      "test shape: (11328, 192, 7) (11328, 192, 7)\n",
      "mse:0.26132458448410034, mae:0.3257283568382263\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 8, 9, 13, 14, 15, 16, 18, 24, 26, 27, 28, 30, 31, 33, 36, 37, 38, 40, 41, 43, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 61, 62, 63, 65, 72, 73, 76, 78, 79, 82, 83, 84, 85, 86, 87, 89, 92, 93, 94, 98, 106, 107, 111, 112, 113, 115, 116, 117, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 9, 10, 13, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 32, 34, 36, 38, 42, 48, 51, 52, 54, 58, 59, 61, 62, 63, 64, 69, 70, 71, 73, 74, 78, 80, 83, 84, 86, 87, 89, 91, 92, 93, 94, 97, 99, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34273\n",
      "val 11329\n",
      "test 11329\n",
      "Epoch: 1 cost time: 337.2938652038574\n",
      "Epoch: 1, Steps: 1071 | Train Loss: 0.3575385 Vali Loss: 0.1796223 Test Loss: 0.2639867\n",
      "Validation loss decreased (inf --> 0.179622).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2, Steps: 1071 | Train Loss: 0.3284265 Vali Loss: 0.1765933 Test Loss: 0.2547082\n",
      "Validation loss decreased (0.179622 --> 0.176593).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 337.00070571899414\n",
      "Epoch: 3, Steps: 1071 | Train Loss: 0.3134913 Vali Loss: 0.1756381 Test Loss: 0.2550016\n",
      "Validation loss decreased (0.176593 --> 0.175638).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 337.1954095363617\n",
      "Epoch: 4, Steps: 1071 | Train Loss: 0.3075624 Vali Loss: 0.1789171 Test Loss: 0.2605255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 336.9837791919708\n",
      "Epoch: 5, Steps: 1071 | Train Loss: 0.3045070 Vali Loss: 0.1794689 Test Loss: 0.2600498\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 337.46149706840515\n",
      "Epoch: 6, Steps: 1071 | Train Loss: 0.3029976 Vali Loss: 0.1797241 Test Loss: 0.2611148\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11329\n",
      "test shape: (354, 32, 192, 7) (354, 32, 192, 7)\n",
      "test shape: (11328, 192, 7) (11328, 192, 7)\n",
      "mse:0.2550016939640045, mae:0.3227977156639099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTm2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTm2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 5, 8, 10, 13, 15, 18, 21, 22, 23, 24, 26, 28, 35, 37, 41, 42, 43, 48, 51, 56, 59, 61, 63, 64, 72, 76, 77, 80, 85, 86, 88, 92, 95, 97, 101, 108, 109, 111, 117, 118, 128, 129, 130, 134, 137, 138, 142, 144, 149, 150, 151, 154, 157, 163, 168, 171, 174, 182, 184, 185, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 4, 8, 10, 12, 13, 24, 27, 34, 35, 37, 41, 44, 45, 46, 49, 50, 52, 64, 66, 70, 73, 76, 81, 83, 86, 92, 95, 98, 100, 106, 107, 108, 111, 113, 115, 118, 120, 121, 124, 128, 131, 133, 138, 139, 140, 141, 142, 144, 147, 151, 152, 154, 155, 157, 163, 167, 169, 170, 174, 179, 184, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTm2_FEDformer_random_modes64_ETTm2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34129\n",
      "val 11185\n",
      "test 11185\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "       # ETTm2\n",
    "        os.system(f\"python -u /kaggle/working/FEDformer/run.py \"\n",
    "                  f\"--is_training 1 \"\n",
    "                  f\"--root_path /kaggle/working/ETDataset/ETT-small \"\n",
    "                  f\"--data_path ETTm2.csv \"\n",
    "                  f\"--task_id ETTm2 \"\n",
    "                  f\"--model FEDformer \"\n",
    "                  f\"--data ETTm2 \"\n",
    "                  f\"--features M \"\n",
    "                  f\"--seq_len 96 \"\n",
    "                  f\"--label_len 48 \"\n",
    "                  f\"--pred_len {pre_len} \"\n",
    "                  f\"--e_layers 2 \"\n",
    "                  f\"--d_layers 1 \"\n",
    "                  f\"--factor 3 \"\n",
    "                  f\"--enc_in 7 \"\n",
    "                  f\"--dec_in 7 \"\n",
    "                  f\"--c_out 7 \"\n",
    "                  f\"--des 'Exp' \"\n",
    "                  f\"--d_model 512 \"\n",
    "                  f\"--itr 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw5dqf7cQneP"
   },
   "source": [
    "## ETTh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T14:31:10.090533Z",
     "iopub.status.busy": "2023-07-15T14:31:10.090181Z",
     "iopub.status.idle": "2023-07-15T16:45:23.390017Z",
     "shell.execute_reply": "2023-07-15T16:45:23.388891Z",
     "shell.execute_reply.started": "2023-07-15T14:31:10.090501Z"
    },
    "id": "W7STuZcDN3vj",
    "outputId": "6bdaabe7-afd1-4080-d9a6-a703deb38d85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 79.28920006752014\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5048379 Vali Loss: 0.2500855 Test Loss: 0.3500820\n",
      "Validation loss decreased (inf --> 0.250085).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.55638980865479\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.4628660 Vali Loss: 0.2492171 Test Loss: 0.3448423\n",
      "Validation loss decreased (0.250085 --> 0.249217).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.06339478492737\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4415519 Vali Loss: 0.2501778 Test Loss: 0.3446147\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 71.97316932678223\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4247860 Vali Loss: 0.2472853 Test Loss: 0.3411542\n",
      "Validation loss decreased (0.249217 --> 0.247285).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 71.89673352241516\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4151164 Vali Loss: 0.2475382 Test Loss: 0.3407257\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.84478211402893\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.4103645 Vali Loss: 0.2481509 Test Loss: 0.3409017\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 72.01559734344482\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.4076851 Vali Loss: 0.2480008 Test Loss: 0.3405265\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.34115418791770935, mae:0.3849283754825592\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.2579653263092\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5034369 Vali Loss: 0.2512112 Test Loss: 0.3487540\n",
      "Validation loss decreased (inf --> 0.251211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.50004458427429\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.4628750 Vali Loss: 0.2475700 Test Loss: 0.3475424\n",
      "Validation loss decreased (0.251211 --> 0.247570).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.15012621879578\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4389636 Vali Loss: 0.2474859 Test Loss: 0.3422522\n",
      "Validation loss decreased (0.247570 --> 0.247486).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.32628107070923\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4200342 Vali Loss: 0.2500292 Test Loss: 0.3460818\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 71.99485158920288\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4092143 Vali Loss: 0.2477332 Test Loss: 0.3416826\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 71.96029710769653\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.4033933 Vali Loss: 0.2490497 Test Loss: 0.3417045\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.3422522246837616, mae:0.3833054006099701\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.19998359680176\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5121538 Vali Loss: 0.2496647 Test Loss: 0.3409448\n",
      "Validation loss decreased (inf --> 0.249665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 3 cost time: 72.20120334625244\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4432217 Vali Loss: 0.2505477 Test Loss: 0.3458431\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.14611387252808\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4258156 Vali Loss: 0.2500316 Test Loss: 0.3444036\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.15166807174683\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4154230 Vali Loss: 0.2485680 Test Loss: 0.3433233\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.34423086047172546, mae:0.38523945212364197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14, 21, 22, 23, 24, 28, 30, 34, 35, 36, 41, 42, 43, 44, 45, 46, 49, 52, 54, 55, 56, 58, 59, 64, 65, 66, 67, 68, 69, 72, 73, 74, 80, 81, 82, 83, 87, 92, 93, 94, 96, 98, 99, 101, 102, 103, 104, 109, 110, 113, 115, 117, 118, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 26, 28, 30, 31, 33, 35, 36, 37, 38, 41, 46, 48, 50, 55, 60, 63, 64, 65, 66, 69, 72, 73, 75, 77, 78, 80, 81, 82, 85, 87, 88, 90, 91, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 109, 111, 117, 118]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 84.71981835365295\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5886694 Vali Loss: 0.3309549 Test Loss: 0.4507491\n",
      "Validation loss decreased (inf --> 0.330955).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.6508846282959\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5503799 Vali Loss: 0.3250661 Test Loss: 0.4426067\n",
      "Validation loss decreased (0.330955 --> 0.325066).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.39541983604431\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.5389142 Vali Loss: 0.3242628 Test Loss: 0.4363568\n",
      "Validation loss decreased (0.325066 --> 0.324263).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.28753995895386\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5307577 Vali Loss: 0.3275771 Test Loss: 0.4413746\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.37289190292358\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.5258688 Vali Loss: 0.3233929 Test Loss: 0.4348572\n",
      "Validation loss decreased (0.324263 --> 0.323393).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 82.11529874801636\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.5232142 Vali Loss: 0.3216421 Test Loss: 0.4332896\n",
      "Validation loss decreased (0.323393 --> 0.321642).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 8 cost time: 82.11081743240356\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.5209290 Vali Loss: 0.3223175 Test Loss: 0.4337327\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 82.31828498840332\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.5206726 Vali Loss: 0.3220555 Test Loss: 0.4333883\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.4332897365093231, mae:0.4409197270870209\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 3, 4, 7, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 26, 27, 30, 31, 34, 36, 37, 38, 42, 43, 45, 46, 51, 54, 58, 59, 62, 63, 65, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 85, 88, 89, 90, 91, 95, 96, 97, 98, 101, 103, 109, 110, 111, 113, 115, 116, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 10, 12, 16, 20, 22, 23, 24, 26, 27, 28, 31, 32, 34, 38, 43, 44, 45, 46, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 64, 66, 69, 70, 73, 80, 81, 82, 84, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 105, 108, 109, 111, 112, 114, 115, 116, 119]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 82.59969711303711\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5994779 Vali Loss: 0.3227073 Test Loss: 0.4289332\n",
      "Validation loss decreased (inf --> 0.322707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.59941267967224\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5542444 Vali Loss: 0.3215214 Test Loss: 0.4235094\n",
      "Validation loss decreased (0.322707 --> 0.321521).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 4 cost time: 82.26277327537537\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5359308 Vali Loss: 0.3276201 Test Loss: 0.4275962\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.3041319847107\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.5319379 Vali Loss: 0.3274488 Test Loss: 0.4266191\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.42350947856903076, mae:0.43501216173171997\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 8, 9, 13, 14, 15, 16, 18, 24, 26, 27, 28, 30, 31, 33, 36, 37, 38, 40, 41, 43, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 61, 62, 63, 65, 72, 73, 76, 78, 79, 82, 83, 84, 85, 86, 87, 89, 92, 93, 94, 98, 106, 107, 111, 112, 113, 115, 116, 117, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 9, 10, 13, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 32, 34, 36, 38, 42, 48, 51, 52, 54, 58, 59, 61, 62, 63, 64, 69, 70, 71, 73, 74, 78, 80, 83, 84, 86, 87, 89, 91, 92, 93, 94, 97, 99, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 82.41107630729675\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5948460 Vali Loss: 0.3155828 Test Loss: 0.4287160\n",
      "Validation loss decreased (inf --> 0.315583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.34835577011108\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5515584 Vali Loss: 0.3205344 Test Loss: 0.4325234\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.54270458221436\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.5379829 Vali Loss: 0.3264988 Test Loss: 0.4370876\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.31194257736206\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5296138 Vali Loss: 0.3246280 Test Loss: 0.4381908\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.4287160634994507, mae:0.43657007813453674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 5, 8, 10, 13, 15, 18, 21, 22, 23, 24, 26, 28, 35, 37, 41, 42, 43, 48, 51, 56, 59, 61, 63, 64, 72, 76, 77, 80, 85, 86, 88, 92, 95, 97, 101, 108, 109, 111, 117, 118, 128, 129, 130, 134, 137, 138, 142, 144, 149, 150, 151, 154, 157, 163, 168, 171, 174, 182, 184, 185, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 4, 8, 10, 12, 13, 24, 27, 34, 35, 37, 41, 44, 45, 46, 49, 50, 52, 64, 66, 70, 73, 76, 81, 83, 86, 92, 95, 98, 100, 106, 107, 108, 111, 113, 115, 118, 120, 121, 124, 128, 131, 133, 138, 139, 140, 141, 142, 144, 147, 151, 152, 154, 155, 157, 163, 167, 169, 170, 174, 179, 184, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 98.97169232368469\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6733288 Vali Loss: 0.4569170 Test Loss: 0.5032100\n",
      "Validation loss decreased (inf --> 0.456917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.13440942764282\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.6283346 Vali Loss: 0.4384112 Test Loss: 0.5040796\n",
      "Validation loss decreased (0.456917 --> 0.438411).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 96.62105917930603\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.6188176 Vali Loss: 0.4407729 Test Loss: 0.5092213\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 96.81956362724304\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.6143624 Vali Loss: 0.4451709 Test Loss: 0.5193937\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 96.78498935699463\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.6119876 Vali Loss: 0.4448560 Test Loss: 0.5202907\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.5040797591209412, mae:0.49512067437171936\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 9, 16, 17, 18, 20, 28, 30, 32, 35, 36, 40, 42, 44, 46, 47, 48, 58, 61, 62, 63, 68, 73, 74, 75, 78, 82, 84, 92, 93, 95, 97, 98, 101, 103, 104, 105, 109, 114, 120, 121, 122, 123, 124, 126, 132, 133, 136, 138, 140, 142, 145, 147, 149, 152, 154, 160, 165, 170, 173, 179, 187, 190, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 6, 13, 14, 15, 17, 18, 20, 21, 23, 26, 27, 28, 32, 38, 42, 54, 58, 59, 61, 62, 63, 65, 69, 70, 71, 74, 79, 82, 83, 84, 86, 91, 92, 94, 97, 98, 101, 102, 103, 108, 110, 114, 120, 123, 125, 127, 130, 132, 133, 138, 139, 154, 155, 156, 158, 161, 173, 179, 183, 187, 190, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 96.75670576095581\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6816538 Vali Loss: 0.4454206 Test Loss: 0.4909754\n",
      "Validation loss decreased (inf --> 0.445421).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.96238660812378\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.6380553 Vali Loss: 0.4352581 Test Loss: 0.4977416\n",
      "Validation loss decreased (0.445421 --> 0.435258).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 97.15838074684143\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.6326862 Vali Loss: 0.4310370 Test Loss: 0.5023937\n",
      "Validation loss decreased (0.435258 --> 0.431037).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 96.94810771942139\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.6279920 Vali Loss: 0.4360024 Test Loss: 0.5052181\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 96.95072388648987\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.6251229 Vali Loss: 0.4317347 Test Loss: 0.4999632\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 96.97166585922241\n",
      "Epoch: 6, Steps: 256 | Train Loss: 0.6243857 Vali Loss: 0.4318185 Test Loss: 0.5006588\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.5023936629295349, mae:0.49159637093544006\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[7, 10, 13, 15, 18, 21, 26, 28, 32, 33, 35, 37, 40, 41, 43, 44, 45, 47, 48, 49, 55, 56, 59, 62, 64, 65, 66, 67, 75, 76, 77, 81, 89, 92, 102, 104, 105, 107, 109, 110, 113, 114, 117, 122, 126, 133, 137, 151, 152, 159, 160, 163, 165, 166, 169, 171, 173, 174, 179, 180, 181, 182, 186, 187]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[3, 4, 5, 6, 7, 10, 11, 13, 14, 15, 19, 28, 31, 33, 40, 42, 49, 50, 52, 53, 56, 64, 65, 70, 72, 73, 76, 79, 82, 88, 91, 93, 95, 96, 105, 112, 113, 114, 119, 121, 122, 125, 127, 131, 135, 136, 139, 143, 144, 147, 148, 149, 150, 154, 160, 163, 168, 171, 177, 178, 185, 186, 188, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 96.91660213470459\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6887240 Vali Loss: 0.4054042 Test Loss: 0.4499444\n",
      "Validation loss decreased (inf --> 0.405404).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 96.94039154052734\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.6585533 Vali Loss: 0.4027644 Test Loss: 0.4452728\n",
      "Validation loss decreased (0.405404 --> 0.402764).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 96.76425552368164\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.6459881 Vali Loss: 0.4158815 Test Loss: 0.4529111\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 96.81300401687622\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.6375171 Vali Loss: 0.4220877 Test Loss: 0.4566241\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 96.9488353729248\n",
      "Epoch: 5, Steps: 256 | Train Loss: 0.6340769 Vali Loss: 0.4199301 Test Loss: 0.4531722\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2545\n",
      "test shape: (79, 32, 336, 7) (79, 32, 336, 7)\n",
      "test shape: (2528, 336, 7) (2528, 336, 7)\n",
      "mse:0.44527286291122437, mae:0.46090564131736755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 2, 8, 13, 34, 35, 37, 41, 44, 46, 50, 52, 64, 66, 76, 95, 104, 108, 124, 125, 129, 134, 137, 139, 140, 142, 150, 156, 161, 169, 179, 180, 194, 204, 208, 211, 213, 219, 222, 242, 251, 261, 262, 263, 270, 271, 289, 291, 297, 298, 301, 303, 307, 313, 317, 319, 321, 322, 336, 347, 351, 352, 372, 381]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 9, 16, 18, 28, 36, 37, 40, 48, 61, 62, 70, 74, 81, 85, 93, 95, 99, 120, 121, 130, 131, 133, 134, 137, 141, 148, 163, 166, 172, 174, 183, 191, 200, 207, 215, 216, 221, 222, 235, 245, 251, 262, 273, 277, 295, 299, 305, 308, 318, 320, 333, 343, 344, 345, 347, 349, 350, 353, 355, 364, 369, 376, 381]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 137.41753268241882\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.8622694 Vali Loss: 0.6599487 Test Loss: 0.4681857\n",
      "Validation loss decreased (inf --> 0.659949).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 135.34921503067017\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.8226102 Vali Loss: 0.6435962 Test Loss: 0.4778922\n",
      "Validation loss decreased (0.659949 --> 0.643596).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 135.30096673965454\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.8134433 Vali Loss: 0.6801206 Test Loss: 0.4704212\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 135.28817343711853\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.8059635 Vali Loss: 0.6806222 Test Loss: 0.4767269\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 135.27826714515686\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.8033347 Vali Loss: 0.6858479 Test Loss: 0.4760523\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.47789210081100464, mae:0.4859660863876343\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 13, 15, 16, 26, 27, 28, 31, 32, 35, 38, 49, 59, 62, 63, 65, 101, 114, 120, 122, 124, 125, 141, 144, 148, 165, 173, 183, 185, 192, 200, 206, 207, 211, 215, 216, 220, 223, 226, 227, 230, 233, 243, 251, 253, 261, 263, 266, 275, 276, 278, 303, 304, 305, 312, 319, 332, 339, 346, 351, 368, 370, 371, 374]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[12, 14, 31, 36, 40, 48, 62, 71, 80, 81, 85, 89, 98, 99, 121, 131, 134, 137, 145, 146, 147, 149, 155, 157, 158, 162, 163, 165, 166, 168, 170, 180, 192, 200, 207, 211, 214, 220, 222, 223, 226, 228, 230, 235, 241, 251, 265, 266, 271, 277, 280, 296, 304, 305, 312, 321, 322, 335, 336, 356, 362, 363, 374, 376]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 135.2598536014557\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.8576213 Vali Loss: 0.6979916 Test Loss: 0.4585053\n",
      "Validation loss decreased (inf --> 0.697992).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.8129896 Vali Loss: 0.6921471 Test Loss: 0.4652711\n",
      "Validation loss decreased (0.697992 --> 0.692147).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 135.10808181762695\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.8064794 Vali Loss: 0.6753804 Test Loss: 0.4536344\n",
      "Validation loss decreased (0.692147 --> 0.675380).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 135.32396578788757\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.8040113 Vali Loss: 0.6783059 Test Loss: 0.4543346\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 135.3236436843872\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.8020787 Vali Loss: 0.6744560 Test Loss: 0.4487883\n",
      "Validation loss decreased (0.675380 --> 0.674456).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 135.33308482170105\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.8008634 Vali Loss: 0.6761535 Test Loss: 0.4501792\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.7996942 Vali Loss: 0.6772791 Test Loss: 0.4510241\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 135.2968394756317\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.7999534 Vali Loss: 0.6775582 Test Loss: 0.4508467\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.44878801703453064, mae:0.4769577085971832\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[5, 6, 22, 30, 32, 68, 73, 76, 77, 78, 83, 85, 86, 87, 89, 94, 106, 124, 125, 131, 133, 144, 145, 148, 160, 164, 171, 185, 186, 187, 194, 198, 204, 213, 217, 222, 228, 232, 241, 242, 254, 256, 257, 258, 260, 270, 278, 288, 290, 294, 296, 300, 302, 306, 319, 325, 330, 335, 336, 340, 344, 352, 366, 373]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[8, 15, 25, 32, 35, 37, 40, 41, 43, 54, 58, 60, 62, 64, 74, 78, 85, 89, 90, 102, 134, 137, 141, 145, 151, 160, 163, 168, 169, 173, 180, 181, 193, 199, 203, 205, 206, 208, 231, 236, 238, 239, 241, 248, 250, 265, 271, 278, 281, 283, 284, 286, 288, 305, 327, 332, 333, 340, 356, 362, 371, 373, 375, 381]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 7825\n",
      "val 2161\n",
      "test 2161\n",
      "Epoch: 1 cost time: 135.23086833953857\n",
      "Epoch: 1, Steps: 244 | Train Loss: 0.8759807 Vali Loss: 0.6540489 Test Loss: 0.4758709\n",
      "Validation loss decreased (inf --> 0.654049).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 135.22182774543762\n",
      "Epoch: 2, Steps: 244 | Train Loss: 0.8388475 Vali Loss: 0.6420997 Test Loss: 0.4747970\n",
      "Validation loss decreased (0.654049 --> 0.642100).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 135.2763020992279\n",
      "Epoch: 3, Steps: 244 | Train Loss: 0.8282782 Vali Loss: 0.6432526 Test Loss: 0.4588973\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 135.16390752792358\n",
      "Epoch: 4, Steps: 244 | Train Loss: 0.8259118 Vali Loss: 0.6388192 Test Loss: 0.4584763\n",
      "Validation loss decreased (0.642100 --> 0.638819).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 135.2720844745636\n",
      "Epoch: 5, Steps: 244 | Train Loss: 0.8240925 Vali Loss: 0.6383162 Test Loss: 0.4554890\n",
      "Validation loss decreased (0.638819 --> 0.638316).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 135.2201578617096\n",
      "Epoch: 6, Steps: 244 | Train Loss: 0.8227862 Vali Loss: 0.6406304 Test Loss: 0.4554323\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 135.16159987449646\n",
      "Epoch: 7, Steps: 244 | Train Loss: 0.8230059 Vali Loss: 0.6392438 Test Loss: 0.4546185\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 135.22422337532043\n",
      "Epoch: 8, Steps: 244 | Train Loss: 0.8229586 Vali Loss: 0.6387126 Test Loss: 0.4550237\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2161\n",
      "test shape: (67, 32, 720, 7) (67, 32, 720, 7)\n",
      "test shape: (2144, 720, 7) (2144, 720, 7)\n",
      "mse:0.4554888904094696, mae:0.4755363464355469\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "        # ETTh1\n",
    "        os.system(f\"python -u /kaggle/working/FEDformer/run.py \"\n",
    "                  f\"--is_training 1 \"\n",
    "                  f\"--root_path /kaggle/working/ETDataset/ETT-small \"\n",
    "                  f\"--data_path ETTh1.csv \"\n",
    "                  f\"--task_id ETTh1 \"\n",
    "                  f\"--model FEDformer \"\n",
    "                  f\"--data ETTh1 \"\n",
    "                  f\"--features M \"\n",
    "                  f\"--seq_len 96 \"\n",
    "                  f\"--label_len 48 \"\n",
    "                  f\"--pred_len {pre_len} \"\n",
    "                  f\"--e_layers 2 \"\n",
    "                  f\"--d_layers 1 \"\n",
    "                  f\"--factor 3 \"\n",
    "                  f\"--enc_in 7 \"\n",
    "                  f\"--dec_in 7 \"\n",
    "                  f\"--c_out 7 \"\n",
    "                  f\"--des 'Exp' \"\n",
    "                  f\"--d_model 512 \"\n",
    "                  f\"--itr 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-7XXI6MQwBF"
   },
   "source": [
    "## ETTh2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T23:24:33.606445Z",
     "iopub.status.busy": "2023-07-15T23:24:33.606065Z"
    },
    "id": "VIEKNqiuPuGW",
    "outputId": "e51039ab-4d19-4d7f-d988-753bbd1f6390"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 74.45921015739441\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5048382 Vali Loss: 0.2500856 Test Loss: 0.3500812\n",
      "Validation loss decreased (inf --> 0.250086).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.21784591674805\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.4628661 Vali Loss: 0.2492185 Test Loss: 0.3448425\n",
      "Validation loss decreased (0.250086 --> 0.249218).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.45465278625488\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4415517 Vali Loss: 0.2501792 Test Loss: 0.3446131\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.27953362464905\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4247848 Vali Loss: 0.2472877 Test Loss: 0.3411546\n",
      "Validation loss decreased (0.249218 --> 0.247288).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.09798073768616\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4151147 Vali Loss: 0.2475405 Test Loss: 0.3407255\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 72.16153335571289\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.4103629 Vali Loss: 0.2481536 Test Loss: 0.3409014\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 72.2079770565033\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.4076837 Vali Loss: 0.2480034 Test Loss: 0.3405262\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.34115469455718994, mae:0.3849286735057831\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.35860347747803\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5034369 Vali Loss: 0.2512112 Test Loss: 0.3487539\n",
      "Validation loss decreased (inf --> 0.251211).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.23742437362671\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.4628750 Vali Loss: 0.2475704 Test Loss: 0.3475422\n",
      "Validation loss decreased (0.251211 --> 0.247570).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.49775695800781\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4389659 Vali Loss: 0.2474861 Test Loss: 0.3422535\n",
      "Validation loss decreased (0.247570 --> 0.247486).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.40605640411377\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4200400 Vali Loss: 0.2500277 Test Loss: 0.3460817\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.29617714881897\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4092220 Vali Loss: 0.2477326 Test Loss: 0.3416815\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 72.51606631278992\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.4034021 Vali Loss: 0.2490477 Test Loss: 0.3417007\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.3422534763813019, mae:0.38330626487731934\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.45072650909424\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.5121538 Vali Loss: 0.2496647 Test Loss: 0.3409443\n",
      "Validation loss decreased (inf --> 0.249665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.23304653167725\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.4661336 Vali Loss: 0.2474873 Test Loss: 0.3442363\n",
      "Validation loss decreased (0.249665 --> 0.247487).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.28007006645203\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.4432230 Vali Loss: 0.2505468 Test Loss: 0.3458486\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.20956563949585\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.4258188 Vali Loss: 0.2500282 Test Loss: 0.3444137\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.44567894935608\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.4154259 Vali Loss: 0.2485663 Test Loss: 0.3433334\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.3442363142967224, mae:0.3852456212043762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14, 21, 22, 23, 24, 28, 30, 34, 35, 36, 41, 42, 43, 44, 45, 46, 49, 52, 54, 55, 56, 58, 59, 64, 65, 66, 67, 68, 69, 72, 73, 74, 80, 81, 82, 83, 87, 92, 93, 94, 96, 98, 99, 101, 102, 103, 104, 109, 110, 113, 115, 117, 118, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 26, 28, 30, 31, 33, 35, 36, 37, 38, 41, 46, 48, 50, 55, 60, 63, 64, 65, 66, 69, 72, 73, 75, 77, 78, 80, 81, 82, 85, 87, 88, 90, 91, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 109, 111, 117, 118]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 84.9379391670227\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5886761 Vali Loss: 0.3309461 Test Loss: 0.4507302\n",
      "Validation loss decreased (inf --> 0.330946).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.66262769699097\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5503936 Vali Loss: 0.3250560 Test Loss: 0.4425918\n",
      "Validation loss decreased (0.330946 --> 0.325056).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.581134557724\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.5389331 Vali Loss: 0.3242367 Test Loss: 0.4363343\n",
      "Validation loss decreased (0.325056 --> 0.324237).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.54708194732666\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5307807 Vali Loss: 0.3275437 Test Loss: 0.4413419\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.55898880958557\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.5258939 Vali Loss: 0.3233570 Test Loss: 0.4348262\n",
      "Validation loss decreased (0.324237 --> 0.323357).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 82.46881651878357\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.5232404 Vali Loss: 0.3216020 Test Loss: 0.4332518\n",
      "Validation loss decreased (0.323357 --> 0.321602).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 82.45558047294617\n",
      "Epoch: 7, Steps: 261 | Train Loss: 0.5216943 Vali Loss: 0.3219175 Test Loss: 0.4331858\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 82.4573757648468\n",
      "Epoch: 8, Steps: 261 | Train Loss: 0.5209559 Vali Loss: 0.3222761 Test Loss: 0.4336943\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 82.41372489929199\n",
      "Epoch: 9, Steps: 261 | Train Loss: 0.5206996 Vali Loss: 0.3220137 Test Loss: 0.4333492\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.4332519769668579, mae:0.44089803099632263\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[2, 3, 4, 7, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 26, 27, 30, 31, 34, 36, 37, 38, 42, 43, 45, 46, 51, 54, 58, 59, 62, 63, 65, 68, 69, 72, 73, 75, 76, 77, 79, 80, 81, 82, 83, 85, 88, 89, 90, 91, 95, 96, 97, 98, 101, 103, 109, 110, 111, 113, 115, 116, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[1, 3, 4, 9, 10, 12, 16, 20, 22, 23, 24, 26, 27, 28, 31, 32, 34, 38, 43, 44, 45, 46, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 64, 66, 69, 70, 73, 80, 81, 82, 84, 86, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 103, 105, 108, 109, 111, 112, 114, 115, 116, 119]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 82.53323221206665\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5994779 Vali Loss: 0.3227073 Test Loss: 0.4289332\n",
      "Validation loss decreased (inf --> 0.322707).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.55816054344177\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5542443 Vali Loss: 0.3215213 Test Loss: 0.4235093\n",
      "Validation loss decreased (0.322707 --> 0.321521).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.59253811836243\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.5429304 Vali Loss: 0.3240740 Test Loss: 0.4263749\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.68339705467224\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5359313 Vali Loss: 0.3276201 Test Loss: 0.4275962\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.63835954666138\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.5319386 Vali Loss: 0.3274488 Test Loss: 0.4266189\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.4235091209411621, mae:0.43501216173171997\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[1, 2, 3, 5, 6, 8, 9, 13, 14, 15, 16, 18, 24, 26, 27, 28, 30, 31, 33, 36, 37, 38, 40, 41, 43, 47, 48, 49, 50, 51, 52, 54, 58, 59, 60, 61, 62, 63, 65, 72, 73, 76, 78, 79, 82, 83, 84, 85, 86, 87, 89, 92, 93, 94, 98, 106, 107, 111, 112, 113, 115, 116, 117, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 9, 10, 13, 14, 15, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 32, 34, 36, 38, 42, 48, 51, 52, 54, 58, 59, 61, 62, 63, 64, 69, 70, 71, 73, 74, 78, 80, 83, 84, 86, 87, 89, 91, 92, 93, 94, 97, 99, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 83.43561959266663\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.5948460 Vali Loss: 0.3155828 Test Loss: 0.4287162\n",
      "Validation loss decreased (inf --> 0.315583).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 82.68553733825684\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.5515586 Vali Loss: 0.3205339 Test Loss: 0.4325231\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.64477252960205\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.5379830 Vali Loss: 0.3264985 Test Loss: 0.4370875\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.65806150436401\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.5296137 Vali Loss: 0.3246278 Test Loss: 0.4381911\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2689\n",
      "test shape: (84, 32, 192, 7) (84, 32, 192, 7)\n",
      "test shape: (2688, 192, 7) (2688, 192, 7)\n",
      "mse:0.42871612310409546, mae:0.43657010793685913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='ETTh2', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='ETTh2', root_path='/kaggle/working/ETDataset/ETT-small', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 3, 5, 8, 10, 13, 15, 18, 21, 22, 23, 24, 26, 28, 35, 37, 41, 42, 43, 48, 51, 56, 59, 61, 63, 64, 72, 76, 77, 80, 85, 86, 88, 92, 95, 97, 101, 108, 109, 111, 117, 118, 128, 129, 130, 134, 137, 138, 142, 144, 149, 150, 151, 154, 157, 163, 168, 171, 174, 182, 184, 185, 191]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 4, 8, 10, 12, 13, 24, 27, 34, 35, 37, 41, 44, 45, 46, 49, 50, 52, 64, 66, 70, 73, 76, 81, 83, 86, 92, 95, 98, 100, 106, 107, 108, 111, 113, 115, 118, 120, 121, 124, 128, 131, 133, 138, 139, 140, 141, 142, 144, 147, 151, 152, 154, 155, 157, 163, 167, 169, 170, 174, 179, 184, 191]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : ETTh2_FEDformer_random_modes64_ETTh2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8209\n",
      "val 2545\n",
      "test 2545\n",
      "Epoch: 1 cost time: 99.30056881904602\n",
      "Epoch: 1, Steps: 256 | Train Loss: 0.6733289 Vali Loss: 0.4569170 Test Loss: 0.5032099\n",
      "Validation loss decreased (inf --> 0.456917).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 97.1595242023468\n",
      "Epoch: 2, Steps: 256 | Train Loss: 0.6283346 Vali Loss: 0.4384113 Test Loss: 0.5040794\n",
      "Validation loss decreased (0.456917 --> 0.438411).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 96.91001987457275\n",
      "Epoch: 3, Steps: 256 | Train Loss: 0.6188176 Vali Loss: 0.4407729 Test Loss: 0.5092213\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 96.96473455429077\n",
      "Epoch: 4, Steps: 256 | Train Loss: 0.6143624 Vali Loss: 0.4451710 Test Loss: 0.5193936\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "        # ETTh2\n",
    "        os.system(f\"python -u /kaggle/working/LTSF-Linear/FEDformer/run.py \"\n",
    "                  f\"--is_training 1 \"\n",
    "                  f\"--root_path /kaggle/working/ETDataset/ETT-small \"\n",
    "                  f\"--data_path ETTh2.csv \"\n",
    "                  f\"--task_id ETTh2 \"\n",
    "                  f\"--model FEDformer \"\n",
    "                  f\"--data ETTh2 \"\n",
    "                  f\"--features M \"\n",
    "                  f\"--seq_len 96 \"\n",
    "                  f\"--label_len 48 \"\n",
    "                  f\"--pred_len {pre_len} \"\n",
    "                  f\"--e_layers 2 \"\n",
    "                  f\"--d_layers 1 \"\n",
    "                  f\"--factor 3 \"\n",
    "                  f\"--enc_in 7 \"\n",
    "                  f\"--dec_in 7 \"\n",
    "                  f\"--c_out 7 \"\n",
    "                  f\"--des 'Exp' \"\n",
    "                  f\"--d_model 512 \"\n",
    "                  f\"--itr 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ipvtqs1PuGT"
   },
   "source": [
    "## Custom data (Energy_consumption_Evaluation)\n",
    "\n",
    "- I run this using kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T13:37:56.729242Z",
     "iopub.status.busy": "2023-07-28T13:37:56.728777Z",
     "iopub.status.idle": "2023-07-28T13:37:57.696572Z",
     "shell.execute_reply": "2023-07-28T13:37:57.695432Z",
     "shell.execute_reply.started": "2023-07-28T13:37:56.729204Z"
    },
    "id": "Bp5m3CYePuGT",
    "outputId": "d066f5ad-7a61-480b-b8ed-7ed3ef89a9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom,Dataset_sin\n",
      "from torch.utils.data import DataLoader\n",
      "\n",
      "data_dict = {\n",
      "    'ETTh1': Dataset_ETT_hour,\n",
      "    'ETTh2': Dataset_ETT_hour,\n",
      "    'ETTm1': Dataset_ETT_minute,\n",
      "    'ETTm2': Dataset_ETT_minute,\n",
      "    'custom': Dataset_Custom,\n",
      "    'sin':Dataset_sin,\n",
      "}\n",
      "\n",
      "\n",
      "def data_provider(args, flag):\n",
      "    Data = data_dict[args.data]\n",
      "    timeenc = 0 if args.embed != 'timeF' else 1\n",
      "\n",
      "    if flag == 'test':\n",
      "        shuffle_flag = False\n",
      "        drop_last = True\n",
      "        batch_size = args.batch_size\n",
      "        freq = args.freq\n",
      "    elif flag == 'pred':\n",
      "        shuffle_flag = False\n",
      "        drop_last = False\n",
      "        batch_size = 1\n",
      "        freq = args.detail_freq\n",
      "        Data = Dataset_Pred\n",
      "    else:\n",
      "        shuffle_flag = True\n",
      "        drop_last = True\n",
      "        batch_size = args.batch_size\n",
      "        freq = args.freq\n",
      "\n",
      "    data_set = Data(\n",
      "        root_path=args.root_path,\n",
      "        data_path=args.data_path,\n",
      "        flag=flag,\n",
      "        size=[args.seq_len, args.label_len, args.pred_len],\n",
      "        features=args.features,\n",
      "        target=args.target,\n",
      "        timeenc=timeenc,\n",
      "        freq=freq\n",
      "    )\n",
      "    print(flag, len(data_set))\n",
      "    data_loader = DataLoader(\n",
      "        data_set,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=shuffle_flag,\n",
      "        num_workers=args.num_workers,\n",
      "        drop_last=drop_last)\n",
      "    return data_set, data_loader\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/LTSF-Linear/FEDformer/data_provider/data_factory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T13:42:10.582695Z",
     "iopub.status.busy": "2023-07-28T13:42:10.582303Z",
     "iopub.status.idle": "2023-07-28T13:42:11.525484Z",
     "shell.execute_reply": "2023-07-28T13:42:11.524204Z",
     "shell.execute_reply.started": "2023-07-28T13:42:10.582660Z"
    },
    "id": "LVvnfoaRPuGU"
   },
   "outputs": [],
   "source": [
    "!sed -i \"s/'custom': Dataset_Custom,/'Energy_consumption_Evaluation_': Dataset_ETT_hour, /g\" /kaggle/working/LTSF-Linear/FEDformer/data_provider/data_factory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T13:42:23.656581Z",
     "iopub.status.busy": "2023-07-28T13:42:23.655775Z",
     "iopub.status.idle": "2023-07-28T13:42:24.756000Z",
     "shell.execute_reply": "2023-07-28T13:42:24.754792Z",
     "shell.execute_reply.started": "2023-07-28T13:42:23.656540Z"
    },
    "id": "Nw93-b-OPuGU",
    "outputId": "0cf49411-57f0-493a-c86d-ac73a5839a6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from data_provider.data_loader import Dataset_ETT_hour, Dataset_ETT_minute, Dataset_Custom,Dataset_sin\n",
      "from torch.utils.data import DataLoader\n",
      "\n",
      "data_dict = {\n",
      "    'ETTh1': Dataset_ETT_hour,\n",
      "    'ETTh2': Dataset_ETT_hour,\n",
      "    'ETTm1': Dataset_ETT_minute,\n",
      "    'ETTm2': Dataset_ETT_minute,\n",
      "    'Energy_consumption_Evaluation_': Dataset_ETT_hour, \n",
      "    'sin':Dataset_sin,\n",
      "}\n",
      "\n",
      "\n",
      "def data_provider(args, flag):\n",
      "    Data = data_dict[args.data]\n",
      "    timeenc = 0 if args.embed != 'timeF' else 1\n",
      "\n",
      "    if flag == 'test':\n",
      "        shuffle_flag = False\n",
      "        drop_last = True\n",
      "        batch_size = args.batch_size\n",
      "        freq = args.freq\n",
      "    elif flag == 'pred':\n",
      "        shuffle_flag = False\n",
      "        drop_last = False\n",
      "        batch_size = 1\n",
      "        freq = args.detail_freq\n",
      "        Data = Dataset_Pred\n",
      "    else:\n",
      "        shuffle_flag = True\n",
      "        drop_last = True\n",
      "        batch_size = args.batch_size\n",
      "        freq = args.freq\n",
      "\n",
      "    data_set = Data(\n",
      "        root_path=args.root_path,\n",
      "        data_path=args.data_path,\n",
      "        flag=flag,\n",
      "        size=[args.seq_len, args.label_len, args.pred_len],\n",
      "        features=args.features,\n",
      "        target=args.target,\n",
      "        timeenc=timeenc,\n",
      "        freq=freq\n",
      "    )\n",
      "    print(flag, len(data_set))\n",
      "    data_loader = DataLoader(\n",
      "        data_set,\n",
      "        batch_size=batch_size,\n",
      "        shuffle=shuffle_flag,\n",
      "        num_workers=args.num_workers,\n",
      "        drop_last=drop_last)\n",
      "    return data_set, data_loader\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/LTSF-Linear/FEDformer/data_provider/data_factory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T13:46:12.372441Z",
     "iopub.status.busy": "2023-07-28T13:46:12.371742Z",
     "iopub.status.idle": "2023-07-28T16:34:06.814392Z",
     "shell.execute_reply": "2023-07-28T16:34:06.813281Z",
     "shell.execute_reply.started": "2023-07-28T13:46:12.372407Z"
    },
    "id": "1NHbQisDPuGV",
    "outputId": "f8bab59c-f204-4c89-c95d-a83be4befadc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "if not os.path.exists(\"/kaggle/working/logs\"):\n",
    "    os.mkdir(\"/kaggle/working/logs\")\n",
    "\n",
    "if not os.path.exists(\"/kaggle/working/logs/LongForecasting\"):\n",
    "    os.mkdir(\"/kaggle/working/logs/LongForecasting\")\n",
    "\n",
    "\n",
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "\n",
    "        # Energy_consumption\n",
    "    os.system(f\"python -u /kaggle/working/LTSF-Linear/FEDformer/run.py \\\n",
    "      --is_training 1 \\\n",
    "      --data_path /kaggle/input/dataset/Energy_consumption_Evaluation_.csv \\\n",
    "      --task_id Energy_consumption_Evaluation_ \\\n",
    "      --model FEDformer  \\\n",
    "      --data Energy_consumption_Evaluation_ \\\n",
    "      --features M \\\n",
    "      --seq_len 96 \\\n",
    "      --label_len 48 \\\n",
    "      --pred_len {pre_len} \\\n",
    "      --e_layers 2 \\\n",
    "      --d_layers 1 \\\n",
    "      --factor 3 \\\n",
    "      --enc_in 7 \\\n",
    "      --dec_in 7 \\\n",
    "      --c_out 7 \\\n",
    "      --des 'Exp' \\\n",
    "      --d_model 512 \\\n",
    "      --itr 3 > /kaggle/working/logs/LongForecasting/Energy_consumption_Evaluation_{pre_len}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:34:07.132711Z",
     "iopub.status.busy": "2023-07-28T16:34:07.132347Z",
     "iopub.status.idle": "2023-07-28T16:34:08.110002Z",
     "shell.execute_reply": "2023-07-28T16:34:08.108796Z",
     "shell.execute_reply.started": "2023-07-28T16:34:07.132677Z"
    },
    "id": "KLbiznBWPuGV",
    "outputId": "b0f5894b-d5c1-43ca-eb5f-fc8820a3ee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/logs/ (stored 0%)\n",
      "  adding: kaggle/working/logs/LongForecasting/ (stored 0%)\n",
      "  adding: kaggle/working/logs/LongForecasting/Energy_consumption_Evaluation_336.log (deflated 77%)\n",
      "  adding: kaggle/working/logs/LongForecasting/Energy_consumption_Evaluation_96.log (deflated 81%)\n",
      "  adding: kaggle/working/logs/LongForecasting/Energy_consumption_Evaluation_192.log (deflated 78%)\n",
      "  adding: kaggle/working/logs/LongForecasting/Energy_consumption_Evaluation_720.log (deflated 75%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='logs.zip' target='_blank'>logs.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/logs.zip"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!zip -r logs.zip /kaggle/working/logs\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'logs.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:34:08.112255Z",
     "iopub.status.busy": "2023-07-28T16:34:08.111894Z",
     "iopub.status.idle": "2023-07-28T16:34:09.097138Z",
     "shell.execute_reply": "2023-07-28T16:34:09.095863Z",
     "shell.execute_reply.started": "2023-07-28T16:34:08.112216Z"
    },
    "id": "t3YjVfXRPuGV",
    "outputId": "39e60d43-b76c-4ccc-947c-d64dd07fa0fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/test_results/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/20.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/40.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/60.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/80.pdf (deflated 25%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/0.pdf (deflated 25%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/20.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/40.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/60.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/80.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/0.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/20.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/40.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/60.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/0.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/20.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/40.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/60.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/0.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/20.pdf (deflated 18%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/40.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/60.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/0.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/20.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/40.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/60.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/80.pdf (deflated 25%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/0.pdf (deflated 25%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/20.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/40.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/60.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/0.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/20.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/40.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/60.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/80.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/0.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/20.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/40.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/60.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/0.pdf (deflated 14%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/20.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/40.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/60.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/0.pdf (deflated 19%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/20.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/40.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/60.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/80.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/0.pdf (deflated 22%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/20.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/40.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/60.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/80.pdf (deflated 26%)\n",
      "  adding: kaggle/working/test_results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/0.pdf (deflated 25%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='test_results.zip' target='_blank'>test_results.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/test_results.zip"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!zip -r test_results.zip /kaggle/working/test_results\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'test_results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:34:09.099589Z",
     "iopub.status.busy": "2023-07-28T16:34:09.099183Z",
     "iopub.status.idle": "2023-07-28T16:34:26.942003Z",
     "shell.execute_reply": "2023-07-28T16:34:26.940832Z",
     "shell.execute_reply.started": "2023-07-28T16:34:09.099548Z"
    },
    "id": "DPyQ3A_CPuGV",
    "outputId": "327226bd-6256-4fff-82ed-d9d2ca1f1a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/results/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/true.npy (deflated 98%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/true.npy (deflated 98%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/true.npy (deflated 99%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2/metrics.npy (deflated 40%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/ (stored 0%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/true.npy (deflated 98%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/pred.npy (deflated 8%)\n",
      "  adding: kaggle/working/results/Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1/metrics.npy (deflated 40%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href='results.zip' target='_blank'>results.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/results.zip"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!zip -r results.zip /kaggle/working/results\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'results.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-28T16:34:26.944406Z",
     "iopub.status.busy": "2023-07-28T16:34:26.944067Z"
    },
    "id": "2Km7WP2aPuGW",
    "outputId": "2fadce3d-731f-47ba-9a4b-de8440b65c7c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='Energy_consumption_Evaluation_', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='Energy_consumption_Evaluation_', root_path='../dataset', data_path='/kaggle/input/dataset/Energy_consumption_Evaluation_.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 75.28956580162048\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.8415597 Vali Loss: 1.1325327 Test Loss: 0.9967888\n",
      "Validation loss decreased (inf --> 1.132533).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 71.98880982398987\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.7071271 Vali Loss: 1.1188846 Test Loss: 1.0155784\n",
      "Validation loss decreased (1.132533 --> 1.118885).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.10406827926636\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.6553951 Vali Loss: 1.1019871 Test Loss: 1.0029416\n",
      "Validation loss decreased (1.118885 --> 1.101987).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 71.87516188621521\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.6312039 Vali Loss: 1.0928142 Test Loss: 0.9945828\n",
      "Validation loss decreased (1.101987 --> 1.092814).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.17659401893616\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.6194259 Vali Loss: 1.0891119 Test Loss: 0.9909383\n",
      "Validation loss decreased (1.092814 --> 1.089112).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 72.2691752910614\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.6132872 Vali Loss: 1.0850680 Test Loss: 0.9864483\n",
      "Validation loss decreased (1.089112 --> 1.085068).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 72.20151424407959\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.6102086 Vali Loss: 1.0854771 Test Loss: 0.9865316\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.13042736053467\n",
      "Epoch: 8, Steps: 264 | Train Loss: 0.6086264 Vali Loss: 1.0852053 Test Loss: 0.9859677\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 71.948734998703\n",
      "Epoch: 9, Steps: 264 | Train Loss: 0.6077841 Vali Loss: 1.0845571 Test Loss: 0.9867092\n",
      "Validation loss decreased (1.085068 --> 1.084557).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 72.22964811325073\n",
      "Epoch: 10, Steps: 264 | Train Loss: 0.6076130 Vali Loss: 1.0844619 Test Loss: 0.9861701\n",
      "Validation loss decreased (1.084557 --> 1.084462).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.98617023229599, mae:0.7398233413696289\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.08863186836243\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.8476641 Vali Loss: 1.1452987 Test Loss: 1.0212725\n",
      "Validation loss decreased (inf --> 1.145299).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.32551145553589\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.7162222 Vali Loss: 1.1176980 Test Loss: 1.0086200\n",
      "Validation loss decreased (1.145299 --> 1.117698).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.46046257019043\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.6609214 Vali Loss: 1.0991794 Test Loss: 1.0070249\n",
      "Validation loss decreased (1.117698 --> 1.099179).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.1871747970581\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.6356421 Vali Loss: 1.0950817 Test Loss: 0.9925606\n",
      "Validation loss decreased (1.099179 --> 1.095082).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.23609352111816\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.6232507 Vali Loss: 1.0856266 Test Loss: 0.9860438\n",
      "Validation loss decreased (1.095082 --> 1.085627).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 72.24562788009644\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.6171416 Vali Loss: 1.0844944 Test Loss: 0.9846120\n",
      "Validation loss decreased (1.085627 --> 1.084494).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 72.10322952270508\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.6139810 Vali Loss: 1.0831522 Test Loss: 0.9859279\n",
      "Validation loss decreased (1.084494 --> 1.083152).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.13505673408508\n",
      "Epoch: 8, Steps: 264 | Train Loss: 0.6124799 Vali Loss: 1.0818685 Test Loss: 0.9846615\n",
      "Validation loss decreased (1.083152 --> 1.081869).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 72.49122595787048\n",
      "Epoch: 9, Steps: 264 | Train Loss: 0.6115742 Vali Loss: 1.0822785 Test Loss: 0.9848272\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 71.98700308799744\n",
      "Epoch: 10, Steps: 264 | Train Loss: 0.6113397 Vali Loss: 1.0819860 Test Loss: 0.9845436\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      ">>>>>>>testing : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.9846616387367249, mae:0.7396304607391357\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 70, 71]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8449\n",
      "val 2785\n",
      "test 2785\n",
      "Epoch: 1 cost time: 72.13013529777527\n",
      "Epoch: 1, Steps: 264 | Train Loss: 0.8424969 Vali Loss: 1.1312517 Test Loss: 1.0048853\n",
      "Validation loss decreased (inf --> 1.131252).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 72.26142883300781\n",
      "Epoch: 2, Steps: 264 | Train Loss: 0.7088369 Vali Loss: 1.1179154 Test Loss: 0.9993549\n",
      "Validation loss decreased (1.131252 --> 1.117915).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 72.26887226104736\n",
      "Epoch: 3, Steps: 264 | Train Loss: 0.6574942 Vali Loss: 1.0989740 Test Loss: 1.0021378\n",
      "Validation loss decreased (1.117915 --> 1.098974).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 72.3132631778717\n",
      "Epoch: 4, Steps: 264 | Train Loss: 0.6339773 Vali Loss: 1.0898883 Test Loss: 0.9870886\n",
      "Validation loss decreased (1.098974 --> 1.089888).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 72.36317944526672\n",
      "Epoch: 5, Steps: 264 | Train Loss: 0.6228516 Vali Loss: 1.0845705 Test Loss: 0.9852103\n",
      "Validation loss decreased (1.089888 --> 1.084571).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 72.23050808906555\n",
      "Epoch: 6, Steps: 264 | Train Loss: 0.6173998 Vali Loss: 1.0818744 Test Loss: 0.9864624\n",
      "Validation loss decreased (1.084571 --> 1.081874).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "Epoch: 7 cost time: 72.40072655677795\n",
      "Epoch: 7, Steps: 264 | Train Loss: 0.6143515 Vali Loss: 1.0800548 Test Loss: 0.9848925\n",
      "Validation loss decreased (1.081874 --> 1.080055).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "Epoch: 8 cost time: 72.50060033798218\n",
      "Epoch: 8, Steps: 264 | Train Loss: 0.6129974 Vali Loss: 1.0805308 Test Loss: 0.9853549\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "Epoch: 9 cost time: 72.49482464790344\n",
      "Epoch: 9, Steps: 264 | Train Loss: 0.6122737 Vali Loss: 1.0807105 Test Loss: 0.9847121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "Epoch: 10 cost time: 72.53989553451538\n",
      "Epoch: 10, Steps: 264 | Train Loss: 0.6119884 Vali Loss: 1.0807261 Test Loss: 0.9841100\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 2785\n",
      "test shape: (87, 32, 96, 7) (87, 32, 96, 7)\n",
      "test shape: (2784, 96, 7) (2784, 96, 7)\n",
      "mse:0.9848925471305847, mae:0.7394462823867798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, task_id='Energy_consumption_Evaluation_', model='FEDformer', version='Fourier', mode_select='random', modes=64, L=3, base='legendre', cross_activation='tanh', data='Energy_consumption_Evaluation_', root_path='../dataset', data_path='/kaggle/input/dataset/Energy_consumption_Evaluation_.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=[24], factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=3, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1')\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "fourier enhanced block used!\n",
      "modes=64, index=[0, 1, 2, 4, 5, 6, 8, 10, 12, 13, 14, 21, 22, 23, 24, 28, 30, 34, 35, 36, 41, 42, 43, 44, 45, 46, 49, 52, 54, 55, 56, 58, 59, 64, 65, 66, 67, 68, 69, 72, 73, 74, 80, 81, 82, 83, 87, 92, 93, 94, 96, 98, 99, 101, 102, 103, 104, 109, 110, 113, 115, 117, 118, 119]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=64, index_q=[0, 1, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 15, 20, 21, 22, 26, 28, 30, 31, 33, 35, 36, 37, 38, 41, 46, 48, 50, 55, 60, 63, 64, 65, 66, 69, 72, 73, 75, 77, 78, 80, 81, 82, 85, 87, 88, 90, 91, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 109, 111, 117, 118]\n",
      "modes_kv=48, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]\n",
      "enc_modes: 48, dec_modes: 64\n",
      ">>>>>>>start training : Energy_consumption_Evaluation__FEDformer_random_modes64_Energy_consumption_Evaluation__ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 8353\n",
      "val 2689\n",
      "test 2689\n",
      "Epoch: 1 cost time: 85.1590325832367\n",
      "Epoch: 1, Steps: 261 | Train Loss: 0.9015488 Vali Loss: 1.2619362 Test Loss: 1.0817437\n",
      "Validation loss decreased (inf --> 1.261936).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "Epoch: 2 cost time: 83.08597874641418\n",
      "Epoch: 2, Steps: 261 | Train Loss: 0.7615686 Vali Loss: 1.2629122 Test Loss: 1.0919702\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "Epoch: 3 cost time: 82.90082359313965\n",
      "Epoch: 3, Steps: 261 | Train Loss: 0.7256991 Vali Loss: 1.2598289 Test Loss: 1.0988404\n",
      "Validation loss decreased (1.261936 --> 1.259829).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "Epoch: 4 cost time: 82.94863104820251\n",
      "Epoch: 4, Steps: 261 | Train Loss: 0.7097591 Vali Loss: 1.2545428 Test Loss: 1.0943887\n",
      "Validation loss decreased (1.259829 --> 1.254543).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "Epoch: 5 cost time: 82.99568486213684\n",
      "Epoch: 5, Steps: 261 | Train Loss: 0.7014209 Vali Loss: 1.2532320 Test Loss: 1.0987943\n",
      "Validation loss decreased (1.254543 --> 1.253232).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "Epoch: 6 cost time: 83.07479429244995\n",
      "Epoch: 6, Steps: 261 | Train Loss: 0.6970688 Vali Loss: 1.2534926 Test Loss: 1.0981373\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n"
     ]
    }
   ],
   "source": [
    "pre_lens = [96, 192, 336, 720]\n",
    "\n",
    "\n",
    "for pre_len in pre_lens:\n",
    "\n",
    "        # Energy_consumption\n",
    "    os.system(f\"python -u /kaggle/working/LTSF-Linear/FEDformer/run.py \\\n",
    "      --is_training 1 \\\n",
    "      --data_path /kaggle/input/dataset/Energy_consumption_Evaluation_.csv \\\n",
    "      --task_id Energy_consumption_Evaluation_ \\\n",
    "      --model FEDformer  \\\n",
    "      --data Energy_consumption_Evaluation_ \\\n",
    "      --features M \\\n",
    "      --seq_len 96 \\\n",
    "      --label_len 48 \\\n",
    "      --pred_len {pre_len} \\\n",
    "      --e_layers 2 \\\n",
    "      --d_layers 1 \\\n",
    "      --factor 3 \\\n",
    "      --enc_in 7 \\\n",
    "      --dec_in 7 \\\n",
    "      --c_out 7 \\\n",
    "      --des 'Exp' \\\n",
    "      --d_model 512 \\\n",
    "      --itr 3\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

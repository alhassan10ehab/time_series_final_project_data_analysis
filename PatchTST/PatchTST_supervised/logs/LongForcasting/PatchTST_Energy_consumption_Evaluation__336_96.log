Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_96', model='PatchTST', data='Energy_consumption_Evaluation_', root_path='./dataset/', data_path='Energy_consumption_Evaluation_.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 336_96_PatchTST_Energy_consumption_Evaluation__ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
Epoch: 1 cost time: 19.394959211349487
Epoch: 1, Steps: 64 | Train Loss: 1.1486142 Vali Loss: 1.2549682 Test Loss: 1.1286402
Validation loss decreased (inf --> 1.254968).  Saving model ...
Updating learning rate to 4.148083589053866e-06
Epoch: 2 cost time: 16.10999321937561
Epoch: 2, Steps: 64 | Train Loss: 0.9937599 Vali Loss: 1.1501112 Test Loss: 1.0217057
Validation loss decreased (1.254968 --> 1.150111).  Saving model ...
Updating learning rate to 4.591420658326014e-06
Epoch: 3 cost time: 16.660927534103394
Epoch: 3, Steps: 64 | Train Loss: 0.9143194 Vali Loss: 1.0997310 Test Loss: 0.9711307
Validation loss decreased (1.150111 --> 1.099731).  Saving model ...
Updating learning rate to 5.327275751800651e-06
Epoch: 4 cost time: 15.615768909454346
Epoch: 4, Steps: 64 | Train Loss: 0.8698391 Vali Loss: 1.0606154 Test Loss: 0.9406570
Validation loss decreased (1.099731 --> 1.060615).  Saving model ...
Updating learning rate to 6.351108533508414e-06
Epoch: 5 cost time: 14.909634828567505
Epoch: 5, Steps: 64 | Train Loss: 0.8380797 Vali Loss: 1.0379039 Test Loss: 0.9179079
Validation loss decreased (1.060615 --> 1.037904).  Saving model ...
Updating learning rate to 7.656601802078191e-06
Epoch: 6 cost time: 27.786722421646118
Epoch: 6, Steps: 64 | Train Loss: 0.8120017 Vali Loss: 1.0097203 Test Loss: 0.8986506
Validation loss decreased (1.037904 --> 1.009720).  Saving model ...
Updating learning rate to 9.235700468814356e-06
Epoch: 7 cost time: 17.929669618606567
Epoch: 7, Steps: 64 | Train Loss: 0.7898197 Vali Loss: 0.9951040 Test Loss: 0.8841051
Validation loss decreased (1.009720 --> 0.995104).  Saving model ...
Updating learning rate to 1.1078661258798536e-05
Epoch: 8 cost time: 16.491119384765625
Epoch: 8, Steps: 64 | Train Loss: 0.7715005 Vali Loss: 0.9828364 Test Loss: 0.8747573
Validation loss decreased (0.995104 --> 0.982836).  Saving model ...
Updating learning rate to 1.3174112828352977e-05
Epoch: 9 cost time: 15.833946228027344
Epoch: 9, Steps: 64 | Train Loss: 0.7578237 Vali Loss: 0.9743139 Test Loss: 0.8659417
Validation loss decreased (0.982836 --> 0.974314).  Saving model ...
Updating learning rate to 1.5509125927931497e-05
Epoch: 10 cost time: 15.846016645431519
Epoch: 10, Steps: 64 | Train Loss: 0.7470209 Vali Loss: 0.9681323 Test Loss: 0.8620948
Validation loss decreased (0.974314 --> 0.968132).  Saving model ...
Updating learning rate to 1.806929317752271e-05
Epoch: 11 cost time: 16.80806565284729
Epoch: 11, Steps: 64 | Train Loss: 0.7392715 Vali Loss: 0.9649063 Test Loss: 0.8584069
Validation loss decreased (0.968132 --> 0.964906).  Saving model ...
Updating learning rate to 2.083881796233921e-05
Epoch: 12 cost time: 16.281845331192017
Epoch: 12, Steps: 64 | Train Loss: 0.7330520 Vali Loss: 0.9609544 Test Loss: 0.8570796
Validation loss decreased (0.964906 --> 0.960954).  Saving model ...
Updating learning rate to 2.3800611900293126e-05
Epoch: 13 cost time: 15.998153924942017
Epoch: 13, Steps: 64 | Train Loss: 0.7279477 Vali Loss: 0.9655493 Test Loss: 0.8586403
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.6936400279869012e-05
Epoch: 14 cost time: 16.786314725875854
Epoch: 14, Steps: 64 | Train Loss: 0.7248223 Vali Loss: 0.9665703 Test Loss: 0.8586819
EarlyStopping counter: 2 out of 20
Updating learning rate to 3.0226834817826824e-05
Epoch: 15 cost time: 16.560628175735474
Epoch: 15, Steps: 64 | Train Loss: 0.7216891 Vali Loss: 0.9503995 Test Loss: 0.8518809
Validation loss decreased (0.960954 --> 0.950400).  Saving model ...
Updating learning rate to 3.365161304100295e-05
Epoch: 16 cost time: 23.38493847846985
Epoch: 16, Steps: 64 | Train Loss: 0.7192666 Vali Loss: 0.9648970 Test Loss: 0.8519379
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.718960355560561e-05
Epoch: 17 cost time: 31.09984016418457
Epoch: 17, Steps: 64 | Train Loss: 0.7171589 Vali Loss: 0.9638356 Test Loss: 0.8567539
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.081897643107481e-05
Epoch: 18 cost time: 16.898194789886475
Epoch: 18, Steps: 64 | Train Loss: 0.7154467 Vali Loss: 0.9598765 Test Loss: 0.8531103
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.4517337894018274e-05
Epoch: 19 cost time: 15.66386866569519
Epoch: 19, Steps: 64 | Train Loss: 0.7130626 Vali Loss: 0.9610799 Test Loss: 0.8537530
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.826186850114219e-05
Epoch: 20 cost time: 16.126695156097412
Epoch: 20, Steps: 64 | Train Loss: 0.7119447 Vali Loss: 0.9607067 Test Loss: 0.8539281
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.202946393862886e-05
Epoch: 21 cost time: 16.001726627349854
Epoch: 21, Steps: 64 | Train Loss: 0.7100608 Vali Loss: 0.9475500 Test Loss: 0.8488225
Validation loss decreased (0.950400 --> 0.947550).  Saving model ...
Updating learning rate to 5.5796877579208066e-05
Epoch: 22 cost time: 16.94799828529358
Epoch: 22, Steps: 64 | Train Loss: 0.7076640 Vali Loss: 0.9718722 Test Loss: 0.8647771
EarlyStopping counter: 1 out of 20
Updating learning rate to 5.954086391732361e-05
Epoch: 23 cost time: 17.677672624588013
Epoch: 23, Steps: 64 | Train Loss: 0.7058073 Vali Loss: 0.9595243 Test Loss: 0.8519410
EarlyStopping counter: 2 out of 20
Updating learning rate to 6.323832199737898e-05
Epoch: 24 cost time: 22.984327793121338
Epoch: 24, Steps: 64 | Train Loss: 0.7039063 Vali Loss: 0.9581100 Test Loss: 0.8490771
EarlyStopping counter: 3 out of 20
Updating learning rate to 6.68664379500879e-05
Epoch: 25 cost time: 20.781362771987915
Epoch: 25, Steps: 64 | Train Loss: 0.7008724 Vali Loss: 0.9738494 Test Loss: 0.8609600
EarlyStopping counter: 4 out of 20
Updating learning rate to 7.040282575745953e-05
Epoch: 26 cost time: 53.393542528152466
Epoch: 26, Steps: 64 | Train Loss: 0.6978941 Vali Loss: 0.9547475 Test Loss: 0.8540660
EarlyStopping counter: 5 out of 20
Updating learning rate to 7.382566537787706e-05
Epoch: 27 cost time: 38.601818799972534
Epoch: 27, Steps: 64 | Train Loss: 0.6951029 Vali Loss: 0.9686576 Test Loss: 0.8617188
EarlyStopping counter: 6 out of 20
Updating learning rate to 7.711383737901773e-05
Epoch: 28 cost time: 22.424346685409546
Epoch: 28, Steps: 64 | Train Loss: 0.6904170 Vali Loss: 0.9663182 Test Loss: 0.8602790
EarlyStopping counter: 7 out of 20
Updating learning rate to 8.024705324790841e-05
Epoch: 29 cost time: 24.891066789627075
Epoch: 29, Steps: 64 | Train Loss: 0.6868189 Vali Loss: 0.9666376 Test Loss: 0.8611342
EarlyStopping counter: 8 out of 20
Updating learning rate to 8.320598057408469e-05
Epoch: 30 cost time: 24.94664192199707
Epoch: 30, Steps: 64 | Train Loss: 0.6806352 Vali Loss: 0.9649638 Test Loss: 0.8636714
EarlyStopping counter: 9 out of 20
Updating learning rate to 8.597236233345446e-05
Epoch: 31 cost time: 24.43535852432251
Epoch: 31, Steps: 64 | Train Loss: 0.6744850 Vali Loss: 0.9694092 Test Loss: 0.8653023
EarlyStopping counter: 10 out of 20
Updating learning rate to 8.852912953686686e-05
Epoch: 32 cost time: 23.842224836349487
Epoch: 32, Steps: 64 | Train Loss: 0.6677903 Vali Loss: 0.9892148 Test Loss: 0.8733789
EarlyStopping counter: 11 out of 20
Updating learning rate to 9.086050654832792e-05
Epoch: 33 cost time: 22.266961097717285
Epoch: 33, Steps: 64 | Train Loss: 0.6604682 Vali Loss: 0.9932992 Test Loss: 0.8729473
EarlyStopping counter: 12 out of 20
Updating learning rate to 9.295210842303365e-05
Epoch: 34 cost time: 42.99918031692505
Epoch: 34, Steps: 64 | Train Loss: 0.6518684 Vali Loss: 0.9936851 Test Loss: 0.8798256
EarlyStopping counter: 13 out of 20
Updating learning rate to 9.479102966463081e-05
Epoch: 35 cost time: 25.14969277381897
Epoch: 35, Steps: 64 | Train Loss: 0.6419324 Vali Loss: 1.0144171 Test Loss: 0.8978707
EarlyStopping counter: 14 out of 20
Updating learning rate to 9.636592385405926e-05
Epoch: 36 cost time: 23.038980722427368
Epoch: 36, Steps: 64 | Train Loss: 0.6331039 Vali Loss: 1.0119070 Test Loss: 0.8792217
EarlyStopping counter: 15 out of 20
Updating learning rate to 9.766707365865438e-05
Epoch: 37 cost time: 19.83226752281189
Epoch: 37, Steps: 64 | Train Loss: 0.6254316 Vali Loss: 1.0176373 Test Loss: 0.8862449
EarlyStopping counter: 16 out of 20
Updating learning rate to 9.86864507895428e-05
Epoch: 38 cost time: 19.26075506210327
Epoch: 38, Steps: 64 | Train Loss: 0.6165430 Vali Loss: 1.0215079 Test Loss: 0.8920796
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.94177655373853e-05
Epoch: 39 cost time: 20.68990421295166
Epoch: 39, Steps: 64 | Train Loss: 0.6082691 Vali Loss: 1.0335114 Test Loss: 0.8924121
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.9856505580824e-05
Epoch: 40 cost time: 23.04758095741272
Epoch: 40, Steps: 64 | Train Loss: 0.6012969 Vali Loss: 1.0505583 Test Loss: 0.9117749
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.999998326693324e-05
Epoch: 41 cost time: 46.86632180213928
Epoch: 41, Steps: 64 | Train Loss: 0.5931013 Vali Loss: 1.0541263 Test Loss: 0.9159376
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_96_PatchTST_Energy_consumption_Evaluation__ftM_sl336_ll48_pl96_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.8488226532936096, mae:0.6895565390586853, rse:0.7665151953697205

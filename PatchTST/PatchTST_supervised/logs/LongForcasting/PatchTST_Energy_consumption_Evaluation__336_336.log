Args in experiment:
Namespace(random_seed=2021, is_training=1, model_id='336_336', model='PatchTST', data='Energy_consumption_Evaluation_', root_path='./dataset/', data_path='Energy_consumption_Evaluation_.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, fc_dropout=0.2, head_dropout=0.0, patch_len=16, stride=8, padding_patch='end', revin=1, affine=0, subtract_last=0, decomposition=0, kernel_size=25, individual=0, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=16, e_layers=3, d_layers=1, d_ff=256, moving_avg=25, factor=1, distil=True, dropout=0.2, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=100, batch_size=128, patience=20, learning_rate=0.0001, des='Exp', loss='mse', lradj='TST', pct_start=0.4, use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:0
>>>>>>>start training : 336_336_PatchTST_Energy_consumption_Evaluation__ftM_sl336_ll48_pl336_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
Epoch: 1 cost time: 25.051977157592773
Epoch: 1, Steps: 62 | Train Loss: 1.2112915 Vali Loss: 1.3247080 Test Loss: 1.2441231
Validation loss decreased (inf --> 1.324708).  Saving model ...
Updating learning rate to 4.148087320607208e-06
Epoch: 2 cost time: 54.20897173881531
Epoch: 2, Steps: 62 | Train Loss: 1.0710196 Vali Loss: 1.2366616 Test Loss: 1.1460708
Validation loss decreased (1.324708 --> 1.236662).  Saving model ...
Updating learning rate to 4.59143553849028e-06
Epoch: 3 cost time: 40.29108715057373
Epoch: 3, Steps: 62 | Train Loss: 1.0006367 Vali Loss: 1.1969291 Test Loss: 1.1012806
Validation loss decreased (1.236662 --> 1.196929).  Saving model ...
Updating learning rate to 5.32730905991248e-06
Epoch: 4 cost time: 24.314794063568115
Epoch: 4, Steps: 62 | Train Loss: 0.9624285 Vali Loss: 1.1742322 Test Loss: 1.0770830
Validation loss decreased (1.196929 --> 1.174232).  Saving model ...
Updating learning rate to 6.351167320786587e-06
Epoch: 5 cost time: 23.59142565727234
Epoch: 5, Steps: 62 | Train Loss: 0.9367088 Vali Loss: 1.1596969 Test Loss: 1.0596977
Validation loss decreased (1.174232 --> 1.159697).  Saving model ...
Updating learning rate to 7.656692803340327e-06
Epoch: 6 cost time: 24.52012062072754
Epoch: 6, Steps: 62 | Train Loss: 0.9147563 Vali Loss: 1.1459137 Test Loss: 1.0461252
Validation loss decreased (1.159697 --> 1.145914).  Saving model ...
Updating learning rate to 9.235830017128029e-06
Epoch: 7 cost time: 22.808346271514893
Epoch: 7, Steps: 62 | Train Loss: 0.8959282 Vali Loss: 1.1356434 Test Loss: 1.0360074
Validation loss decreased (1.145914 --> 1.135643).  Saving model ...
Updating learning rate to 1.1078835203863851e-05
Epoch: 8 cost time: 24.96327018737793
Epoch: 8, Steps: 62 | Train Loss: 0.8809998 Vali Loss: 1.1257536 Test Loss: 1.0282526
Validation loss decreased (1.135643 --> 1.125754).  Saving model ...
Updating learning rate to 1.3174336459382388e-05
Epoch: 9 cost time: 42.599809885025024
Epoch: 9, Steps: 62 | Train Loss: 0.8689437 Vali Loss: 1.1204450 Test Loss: 1.0225806
Validation loss decreased (1.125754 --> 1.120445).  Saving model ...
Updating learning rate to 1.5509403901756215e-05
Epoch: 10 cost time: 22.825547456741333
Epoch: 10, Steps: 62 | Train Loss: 0.8594704 Vali Loss: 1.1182134 Test Loss: 1.0185940
Validation loss decreased (1.120445 --> 1.118213).  Saving model ...
Updating learning rate to 1.806962945261123e-05
Epoch: 11 cost time: 23.847617387771606
Epoch: 11, Steps: 62 | Train Loss: 0.8528551 Vali Loss: 1.1144590 Test Loss: 1.0188060
Validation loss decreased (1.118213 --> 1.114459).  Saving model ...
Updating learning rate to 2.08392157393651e-05
Epoch: 12 cost time: 23.693191528320312
Epoch: 12, Steps: 62 | Train Loss: 0.8481349 Vali Loss: 1.1153021 Test Loss: 1.0165976
EarlyStopping counter: 1 out of 20
Updating learning rate to 2.3801073569834657e-05
Epoch: 13 cost time: 22.02521824836731
Epoch: 13, Steps: 62 | Train Loss: 0.8439662 Vali Loss: 1.1143537 Test Loss: 1.0166583
Validation loss decreased (1.114459 --> 1.114354).  Saving model ...
Updating learning rate to 2.6936927377764345e-05
Epoch: 14 cost time: 24.55620050430298
Epoch: 14, Steps: 62 | Train Loss: 0.8409592 Vali Loss: 1.1151063 Test Loss: 1.0121633
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.022742798864445e-05
Epoch: 15 cost time: 50.41953229904175
Epoch: 15, Steps: 62 | Train Loss: 0.8377435 Vali Loss: 1.1142299 Test Loss: 1.0105323
Validation loss decreased (1.114354 --> 1.114230).  Saving model ...
Updating learning rate to 3.3652272010019945e-05
Epoch: 16 cost time: 50.31305766105652
Epoch: 16, Steps: 62 | Train Loss: 0.8352837 Vali Loss: 1.1201223 Test Loss: 1.0097347
EarlyStopping counter: 1 out of 20
Updating learning rate to 3.719032710961484e-05
Epoch: 17 cost time: 22.987591981887817
Epoch: 17, Steps: 62 | Train Loss: 0.8324415 Vali Loss: 1.1167318 Test Loss: 1.0116764
EarlyStopping counter: 2 out of 20
Updating learning rate to 4.081976240826834e-05
Epoch: 18 cost time: 23.401251554489136
Epoch: 18, Steps: 62 | Train Loss: 0.8297473 Vali Loss: 1.1162724 Test Loss: 1.0046622
EarlyStopping counter: 3 out of 20
Updating learning rate to 4.451818318311814e-05
Epoch: 19 cost time: 24.881121397018433
Epoch: 19, Steps: 62 | Train Loss: 0.8284140 Vali Loss: 1.1143782 Test Loss: 1.0034726
EarlyStopping counter: 4 out of 20
Updating learning rate to 4.8262769049871535e-05
Epoch: 20 cost time: 21.75317668914795
Epoch: 20, Steps: 62 | Train Loss: 0.8254381 Vali Loss: 1.1170276 Test Loss: 1.0015503
EarlyStopping counter: 5 out of 20
Updating learning rate to 5.2030414771537206e-05
Epoch: 21 cost time: 22.145795106887817
Epoch: 21, Steps: 62 | Train Loss: 0.8207371 Vali Loss: 1.1247791 Test Loss: 1.0091692
EarlyStopping counter: 6 out of 20
Updating learning rate to 5.579787282478523e-05
Epoch: 22 cost time: 52.21259880065918
Epoch: 22, Steps: 62 | Train Loss: 0.8156251 Vali Loss: 1.1277125 Test Loss: 1.0118734
EarlyStopping counter: 7 out of 20
Updating learning rate to 5.954189684425702e-05
Epoch: 23 cost time: 43.49752640724182
Epoch: 23, Steps: 62 | Train Loss: 0.8100708 Vali Loss: 1.1314597 Test Loss: 1.0213258
EarlyStopping counter: 8 out of 20
Updating learning rate to 6.323938505973041e-05
Epoch: 24 cost time: 24.108854055404663
Epoch: 24, Steps: 62 | Train Loss: 0.8042798 Vali Loss: 1.1436840 Test Loss: 1.0249226
EarlyStopping counter: 9 out of 20
Updating learning rate to 6.686752284108843e-05
Epoch: 25 cost time: 22.43802499771118
Epoch: 25, Steps: 62 | Train Loss: 0.7987827 Vali Loss: 1.1583482 Test Loss: 1.0497732
EarlyStopping counter: 10 out of 20
Updating learning rate to 7.040392347154635e-05
Epoch: 26 cost time: 22.062575101852417
Epoch: 26, Steps: 62 | Train Loss: 0.7937642 Vali Loss: 1.1627976 Test Loss: 1.0437528
EarlyStopping counter: 11 out of 20
Updating learning rate to 7.382676628052255e-05
Epoch: 27 cost time: 23.36611318588257
Epoch: 27, Steps: 62 | Train Loss: 0.7870365 Vali Loss: 1.1558371 Test Loss: 1.0505325
EarlyStopping counter: 12 out of 20
Updating learning rate to 7.711493128383196e-05
Epoch: 28 cost time: 37.34151077270508
Epoch: 28, Steps: 62 | Train Loss: 0.7808122 Vali Loss: 1.1580185 Test Loss: 1.0508740
EarlyStopping counter: 13 out of 20
Updating learning rate to 8.02481295004307e-05
Epoch: 29 cost time: 50.26225662231445
Epoch: 29, Steps: 62 | Train Loss: 0.7751617 Vali Loss: 1.1723056 Test Loss: 1.0564836
EarlyStopping counter: 14 out of 20
Updating learning rate to 8.32070281416176e-05
Epoch: 30 cost time: 25.556522130966187
Epoch: 30, Steps: 62 | Train Loss: 0.7667984 Vali Loss: 1.1882066 Test Loss: 1.0757228
EarlyStopping counter: 15 out of 20
Updating learning rate to 8.59733699002376e-05
Epoch: 31 cost time: 22.798423290252686
Epoch: 31, Steps: 62 | Train Loss: 0.7586267 Vali Loss: 1.1662607 Test Loss: 1.0561124
EarlyStopping counter: 16 out of 20
Updating learning rate to 8.853008560383577e-05
Epoch: 32 cost time: 22.687793016433716
Epoch: 32, Steps: 62 | Train Loss: 0.7509824 Vali Loss: 1.1837509 Test Loss: 1.0658844
EarlyStopping counter: 17 out of 20
Updating learning rate to 9.086139953665796e-05
Epoch: 33 cost time: 20.46944761276245
Epoch: 33, Steps: 62 | Train Loss: 0.7432558 Vali Loss: 1.1729245 Test Loss: 1.0575451
EarlyStopping counter: 18 out of 20
Updating learning rate to 9.29529267806289e-05
Epoch: 34 cost time: 20.00283694267273
Epoch: 34, Steps: 62 | Train Loss: 0.7351981 Vali Loss: 1.1761743 Test Loss: 1.0517803
EarlyStopping counter: 19 out of 20
Updating learning rate to 9.47917619746846e-05
Epoch: 35 cost time: 52.41041278839111
Epoch: 35, Steps: 62 | Train Loss: 0.7264402 Vali Loss: 1.1870492 Test Loss: 1.0603524
EarlyStopping counter: 20 out of 20
Early stopping
>>>>>>>testing : 336_336_PatchTST_Energy_consumption_Evaluation__ftM_sl336_ll48_pl336_dm128_nh16_el3_dl1_df256_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
mse:1.0105321407318115, mae:0.7620817422866821, rse:0.8345028162002563
